#!/usr/bin/env python3
"""Generate an Ollama Modelfile from a merged model directory."""

from __future__ import annotations

import argparse
from pathlib import Path


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Prepare Ollama Modelfile")
    parser.add_argument("--merged-model-dir", required=True, help="Path to merged HF model")
    parser.add_argument("--gguf-path", default="/absolute/path/to/model.gguf", help="Path to GGUF")
    parser.add_argument("--modelfile-out", default="Modelfile", help="Output Modelfile path")
    parser.add_argument(
        "--system",
        default="You are a helpful assistant specialized for my domain.",
        help="System prompt for Ollama model",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    merged_dir = Path(args.merged_model_dir)
    if not merged_dir.exists():
        raise FileNotFoundError(f"Merged model directory not found: {merged_dir}")

    modelfile_content = (
        f"# Generated by prepare_ollama_model.py\n"
        f"# Merged model dir: {merged_dir.resolve()}\n"
        f"FROM {args.gguf_path}\n"
        f"SYSTEM \"{args.system}\"\n"
        "PARAMETER temperature 0.2\n"
        "PARAMETER num_ctx 4096\n"
    )

    output_path = Path(args.modelfile_out)
    output_path.write_text(modelfile_content, encoding="utf-8")
    print(f"Wrote {output_path}")
    print("Next steps:")
    print("1) Replace --gguf-path with your real GGUF file path.")
    print(f"2) ollama create my-llama-ft -f {output_path}")
    print("3) ollama run my-llama-ft")


if __name__ == "__main__":
    main()
